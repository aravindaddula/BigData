{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0317884-17a5-4143-9005-8798e99c1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration : use this command to run pyspark shell rather than just pyspark command\n",
    "pyspark --packages org.apache.hudi:hudi-spark$SPARK_VERSION-bundle_2.12:0.14.1 \\\n",
    "        --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer' \\\n",
    "        --conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.hudi.catalog.HoodieCatalog' \\\n",
    "        --conf 'spark.sql.extensions=org.apache.spark.sql.hudi.HoodieSparkSessionExtension' \\\n",
    "        --conf 'spark.kryo.registrator=org.apache.spark.HoodieSparkKryoRegistrar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2505e-c38d-4ed4-bb73-df83716be806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/08 21:33:19 WARN Utils: Your hostname, jarvis resolves to a loopback address: 127.0.1.1; using 192.168.29.176 instead (on interface wlp2s0)\n",
      "24/06/08 21:33:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/tony/.ivy2/cache\n",
      "The jars for the packages stored in: /home/tony/.ivy2/jars\n",
      "org.apache.hudi#hudi-spark-bundle_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fc1da398-8d45-4a1d-9fe2-e0e395a6ad35;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hudi#hudi-spark-bundle_2.12;0.14.1 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hudi/hudi-spark-bundle_2.12/0.14.1/hudi-spark-bundle_2.12-0.14.1.jar ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Intended to write data in s3 with specific hudi schema and create hudi table in athena for quering purpose.\n",
    "\"\"\"\n",
    "                                                                                      \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HudiExample\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"ts\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create a sample dataframe\n",
    "data = [(\"1\", \"Alice\", 21, \"2024-06-08T00:00:00Z\"),\n",
    "        (\"2\", \"Bob\", 22, \"2024-06-08T00:00:00Z\")]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Write dataframe to Hudi table\n",
    "hudi_options = {\n",
    "    'hoodie.table.name': 'hudi_table',\n",
    "    'hoodie.datasource.write.recordkey.field': 'id',\n",
    "    'hoodie.datasource.write.partitionpath.field': '',\n",
    "    'hoodie.datasource.write.table.name': 'hudi_table',\n",
    "    'hoodie.datasource.write.operation': 'insert',\n",
    "    'hoodie.upsert.shuffle.parallelism': 2,\n",
    "    'hoodie.insert.shuffle.parallelism': 2\n",
    "}\n",
    "\n",
    "output_path = \"s3://avengersmagicbucket/hudi_practice/\"\n",
    "\n",
    "df.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
