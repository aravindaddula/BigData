{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5db50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to postgres\n",
    "from spark_session import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dd189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_configs = {\n",
    "    \"host\":\"localhost\",\n",
    "    \"port\":\"5432\",\n",
    "    \"user\":\"jarvis\",\n",
    "    \"password\":\"2650\"\n",
    "}\n",
    "\n",
    "jdbc_url = 'jdbc:postgresql://localhost:5432/avengers'\n",
    "\n",
    "# spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64a4a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/30 08:31:44 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "25/06/30 08:31:44 INFO SparkContext: Starting job: parquet at <unknown>:0\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Got job 81 (parquet at <unknown>:0) with 1 output partitions\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Final stage: ResultStage 89 (parquet at <unknown>:0)\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[244] at parquet at <unknown>:0), which has no missing parents\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 104.8 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on localhost:44471 (size: 37.9 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[244] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 102) (localhost, executor driver, partition 0, PROCESS_LOCAL, 9561 bytes) \n",
      "25/06/30 08:31:44 INFO Executor: Running task 0.0 in stage 89.0 (TID 102)\n",
      "25/06/30 08:31:44 INFO Executor: Finished task 0.0 in stage 89.0 (TID 102). 2289 bytes result sent to driver\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 102) in 13 ms on localhost (executor driver) (1/1)\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:44 INFO DAGScheduler: ResultStage 89 (parquet at <unknown>:0) finished in 0.027 s\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Job 81 finished: parquet at <unknown>:0, took 0.029928 s\n",
      "25/06/30 08:31:44 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/30 08:31:44 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 203.4 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Removed broadcast_102_piece0 on localhost:44471 in memory (size: 35.7 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Removed broadcast_105_piece0 on localhost:44471 in memory (size: 193.0 B, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on localhost:44471 (size: 35.7 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO SparkContext: Created broadcast 108 from parquet at <unknown>:0\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Removed broadcast_107_piece0 on localhost:44471 in memory (size: 37.9 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Removed broadcast_106_piece0 on localhost:44471 in memory (size: 7.9 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Registering RDD 249 (parquet at <unknown>:0) as input to shuffle 8\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Got map stage job 82 (parquet at <unknown>:0) with 3 output partitions\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Final stage: ShuffleMapStage 90 (parquet at <unknown>:0)\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[249] at parquet at <unknown>:0), which has no missing parents\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 18.7 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on localhost:44471 (size: 8.3 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[249] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Adding task set 90.0 with 3 tasks resource profile 0\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 103) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:44 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 104) (localhost, executor driver, partition 1, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:44 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 105) (localhost, executor driver, partition 2, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:44 INFO Executor: Running task 1.0 in stage 90.0 (TID 104)\n",
      "25/06/30 08:31:44 INFO Executor: Running task 0.0 in stage 90.0 (TID 103)\n",
      "25/06/30 08:31:44 INFO Executor: Running task 2.0 in stage 90.0 (TID 105)\n",
      "25/06/30 08:31:44 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-47416abc-bca3-443f-bad7-416971e44618-c000.snappy.parquet, range: 0-1442, partition values: [empty row]\n",
      "25/06/30 08:31:44 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-eb4662a2-8b04-4bfd-9bd9-3883b6844c97-c000.snappy.parquet, range: 0-1392, partition values: [empty row]\n",
      "25/06/30 08:31:44 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-ab172deb-097b-47aa-a03a-c2f690cec0af-c000.snappy.parquet, range: 0-1442, partition values: [empty row]\n",
      "25/06/30 08:31:44 INFO Executor: Finished task 1.0 in stage 90.0 (TID 104). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:44 INFO Executor: Finished task 2.0 in stage 90.0 (TID 105). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:44 INFO Executor: Finished task 0.0 in stage 90.0 (TID 103). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 104) in 21 ms on localhost (executor driver) (1/3)\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 103) in 23 ms on localhost (executor driver) (2/3)\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 105) in 23 ms on localhost (executor driver) (3/3)\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:44 INFO DAGScheduler: ShuffleMapStage 90 (parquet at <unknown>:0) finished in 0.032 s\n",
      "25/06/30 08:31:44 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/30 08:31:44 INFO DAGScheduler: running: Set()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: waiting: Set()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: failed: Set()\n",
      "25/06/30 08:31:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Got job 83 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Final stage: ResultStage 92 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[253] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 13.3 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on localhost:44471 (size: 6.2 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[253] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 106) (localhost, executor driver, partition 0, NODE_LOCAL, 9369 bytes) \n",
      "25/06/30 08:31:44 INFO Executor: Running task 0.0 in stage 92.0 (TID 106)\n",
      "25/06/30 08:31:44 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/30 08:31:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/30 08:31:44 INFO Executor: Finished task 0.0 in stage 92.0 (TID 106). 4136 bytes result sent to driver\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Removed broadcast_109_piece0 on localhost:44471 in memory (size: 8.3 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 106) in 21 ms on localhost (executor driver) (1/1)\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:44 INFO DAGScheduler: ResultStage 92 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.028 s\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/30 08:31:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "25/06/30 08:31:44 INFO DAGScheduler: Job 83 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.032109 s\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 120.0 B, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 193.0 B, free 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on localhost:44471 (size: 193.0 B, free: 7.8 GiB)\n",
      "25/06/30 08:31:44 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/06/30 08:31:45 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/06/30 08:31:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/06/30 08:31:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/06/30 08:31:45 INFO SparkContext: Starting job: parquet at <unknown>:0\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Got job 84 (parquet at <unknown>:0) with 1 output partitions\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Final stage: ResultStage 93 (parquet at <unknown>:0)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[256] at parquet at <unknown>:0), which has no missing parents\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 219.6 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 79.8 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on localhost:44471 (size: 79.8 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[256] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 107) (localhost, executor driver, partition 0, PROCESS_LOCAL, 9215 bytes) \n",
      "25/06/30 08:31:45 INFO Executor: Running task 0.0 in stage 93.0 (TID 107)\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/06/30 08:31:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/06/30 08:31:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/06/30 08:31:45 INFO CodecConfig: Compression: SNAPPY\n",
      "25/06/30 08:31:45 INFO CodecConfig: Compression: SNAPPY\n",
      "25/06/30 08:31:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "25/06/30 08:31:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"id\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : true,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"unique_key\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(100)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"value\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"updated_at\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 id;\n",
      "  optional binary unique_key (STRING);\n",
      "  optional binary value (STRING);\n",
      "  optional int96 updated_at;\n",
      "}\n",
      "\n",
      "       \n",
      "25/06/30 08:31:45 INFO JDBCRDD: closed connection\n",
      "25/06/30 08:31:45 INFO FileOutputCommitter: Saved output of task 'attempt_202506300831452441467416068477801_0093_m_000000_107' to file:/home/jarvis/BigData/Template_Generation/target_files/records/_temporary/0/task_202506300831452441467416068477801_0093_m_000000\n",
      "25/06/30 08:31:45 INFO SparkHadoopMapRedUtil: attempt_202506300831452441467416068477801_0093_m_000000_107: Committed. Elapsed time: 0 ms.\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 0.0 in stage 93.0 (TID 107). 2497 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 107) in 65 ms on localhost (executor driver) (1/1)\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:45 INFO DAGScheduler: ResultStage 93 (parquet at <unknown>:0) finished in 0.110 s\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 84 finished: parquet at <unknown>:0, took 0.113718 s\n",
      "25/06/30 08:31:45 INFO FileFormatWriter: Start to commit write Job 29459db4-1027-47bd-a37b-4e57a1e197f0.\n",
      "25/06/30 08:31:45 INFO FileFormatWriter: Write Job 29459db4-1027-47bd-a37b-4e57a1e197f0 committed. Elapsed time: 13 ms.\n",
      "25/06/30 08:31:45 INFO FileFormatWriter: Finished processing stats for write job 29459db4-1027-47bd-a37b-4e57a1e197f0.\n",
      "25/06/30 08:31:45 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/30 08:31:45 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 203.4 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on localhost:44471 (size: 35.7 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 113 from showString at <unknown>:0\n",
      "25/06/30 08:31:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Registering RDD 261 (showString at <unknown>:0) as input to shuffle 9\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Got map stage job 85 (showString at <unknown>:0) with 3 output partitions\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (showString at <unknown>:0)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[261] at showString at <unknown>:0), which has no missing parents\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 18.7 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on localhost:44471 (size: 8.3 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_111_piece0 on localhost:44471 in memory (size: 193.0 B, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[261] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Adding task set 94.0 with 3 tasks resource profile 0\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 108) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 109) (localhost, executor driver, partition 1, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_108_piece0 on localhost:44471 in memory (size: 35.7 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 110) (localhost, executor driver, partition 2, PROCESS_LOCAL, 10057 bytes) \n",
      "25/06/30 08:31:45 INFO Executor: Running task 1.0 in stage 94.0 (TID 109)\n",
      "25/06/30 08:31:45 INFO Executor: Running task 2.0 in stage 94.0 (TID 110)\n",
      "25/06/30 08:31:45 INFO Executor: Running task 0.0 in stage 94.0 (TID 108)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_112_piece0 on localhost:44471 in memory (size: 79.8 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-eb4662a2-8b04-4bfd-9bd9-3883b6844c97-c000.snappy.parquet, range: 0-1392, partition values: [empty row]\n",
      "25/06/30 08:31:45 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-47416abc-bca3-443f-bad7-416971e44618-c000.snappy.parquet, range: 0-1442, partition values: [empty row]\n",
      "25/06/30 08:31:45 INFO FileScanRDD: Reading File path: file:///home/jarvis/BigData/Template_Generation/target_files/records/part-00000-ab172deb-097b-47aa-a03a-c2f690cec0af-c000.snappy.parquet, range: 0-1442, partition values: [empty row]\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 0.0 in stage 94.0 (TID 108). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_110_piece0 on localhost:44471 in memory (size: 6.2 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 1.0 in stage 94.0 (TID 109). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 108) in 27 ms on localhost (executor driver) (1/3)\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 2.0 in stage 94.0 (TID 110). 2133 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 109) in 26 ms on localhost (executor driver) (2/3)\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 110) in 25 ms on localhost (executor driver) (3/3)\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:45 INFO DAGScheduler: ShuffleMapStage 94 (showString at <unknown>:0) finished in 0.051 s\n",
      "25/06/30 08:31:45 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/30 08:31:45 INFO DAGScheduler: running: Set()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: waiting: Set()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: failed: Set()\n",
      "25/06/30 08:31:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Got job 86 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Final stage: ResultStage 96 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[265] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 13.3 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on localhost:44471 (size: 6.2 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[265] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 111) (localhost, executor driver, partition 0, NODE_LOCAL, 9369 bytes) \n",
      "25/06/30 08:31:45 INFO Executor: Running task 0.0 in stage 96.0 (TID 111)\n",
      "25/06/30 08:31:45 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/30 08:31:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 0.0 in stage 96.0 (TID 111). 4050 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 111) in 10 ms on localhost (executor driver) (1/1)\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:45 INFO DAGScheduler: ResultStage 96 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.016 s\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 86 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.019084 s\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 120.0 B, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 193.0 B, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on localhost:44471 (size: 193.0 B, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 116 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/06/30 08:31:45 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Got job 87 (showString at <unknown>:0) with 1 output partitions\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Final stage: ResultStage 97 (showString at <unknown>:0)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[268] at showString at <unknown>:0), which has no missing parents\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 15.7 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on localhost:44471 (size: 7.9 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_114_piece0 on localhost:44471 in memory (size: 8.3 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[268] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 112) (localhost, executor driver, partition 0, PROCESS_LOCAL, 9215 bytes) \n",
      "25/06/30 08:31:45 INFO Executor: Running task 0.0 in stage 97.0 (TID 112)\n",
      "25/06/30 08:31:45 INFO BlockManagerInfo: Removed broadcast_115_piece0 on localhost:44471 in memory (size: 6.2 KiB, free: 7.8 GiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+----------+\n",
      "| id|unique_key|value|updated_at|\n",
      "+---+----------+-----+----------+\n",
      "+---+----------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/30 08:31:45 INFO JDBCRDD: closed connection\n",
      "25/06/30 08:31:45 INFO Executor: Finished task 0.0 in stage 97.0 (TID 112). 1508 bytes result sent to driver\n",
      "25/06/30 08:31:45 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 112) in 30 ms on localhost (executor driver) (1/1)\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "25/06/30 08:31:45 INFO DAGScheduler: ResultStage 97 (showString at <unknown>:0) finished in 0.049 s\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/30 08:31:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "25/06/30 08:31:45 INFO DAGScheduler: Job 87 finished: showString at <unknown>:0, took 0.052601 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/30 08:42:03 INFO BlockManagerInfo: Removed broadcast_117_piece0 on localhost:44471 in memory (size: 7.9 KiB, free: 7.8 GiB)\n",
      "25/06/30 08:42:03 INFO BlockManagerInfo: Removed broadcast_116_piece0 on localhost:44471 in memory (size: 193.0 B, free: 7.8 GiB)\n",
      "25/06/30 08:42:03 INFO BlockManagerInfo: Removed broadcast_113_piece0 on localhost:44471 in memory (size: 35.7 KiB, free: 7.8 GiB)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType,TimestampType,StringType\n",
    "\n",
    "records_schema = StructType([\n",
    "    StructField(\"id\",IntegerType()),\n",
    "    StructField(\"unique_key\",StringType()),\n",
    "    StructField(\"value\",StringType()),\n",
    "    StructField(\"updated_at\",TimestampType())\n",
    "])\n",
    "\n",
    "table='records'\n",
    "\n",
    "tgt_file = f'./target_files/{table}'\n",
    "try:\n",
    "    tgt_tbl = spark.read.parquet(tgt_file)\n",
    "    src = spark.read.jdbc(url=jdbc_url,table=table,properties=jdbc_configs)\n",
    "    tgt_timestamp = tgt_tbl.selectExpr(\"max(updated_at) as max_updated_at\")\n",
    "    src = src.alias(\"src\")\n",
    "    tgt = tgt_timestamp.alias(\"tgt\")\n",
    "    filtered = src.crossJoin(tgt).select(\"src.*\").where(\"src.updated_at > tgt.max_updated_at\")\n",
    "    filtered.write.mode(\"append\").option(\"header\",True).parquet(f'{tgt_file}')\n",
    "    # tgt.show()\n",
    "    filtered.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05242d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/29 22:09:18 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "# src.printSchema()\n",
    "# df.printSchema()\n",
    "# src.printSchema()\n",
    "# assert src.schema == df.schema,\"Schema error Triggered\"\n",
    "\n",
    "\n",
    "# tgt.show()\n",
    "\n",
    "# print(src.schema)\n",
    "# print(tgt.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58192fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
