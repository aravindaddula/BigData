{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7450e07-6f12-44dd-822f-5851898390a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# create RDD\n",
    "rdd=sc.parallelize([1,2,3,4,5])\n",
    "\n",
    "# Apply transformation on it\n",
    "getSquares=rdd.map(lambda num:num*num).take(5)\n",
    "print(getSquares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cf77374-ad35-4e8e-bf7c-52d4bd185846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Filter words that starting with letter 'A' or 'a' and store into a text file\n",
    "# Read a text file from locally \n",
    "rdd=sc.textFile('file:///home/tony/BigData/Files/Sample.txt')\n",
    "\n",
    "# split these elements into words and ,flatten the nested list into sigle array using flatMap()\n",
    "splitWords=rdd.flatMap(lambda word:word.split())\n",
    "filterWords=splitWords.filter(lambda word:word.startswith('a'))\n",
    "# ''.join(filterWords).collect()\n",
    "# filterWords.count();\n",
    "finalWords=filterWords.distinct().saveAsTextFile('file:///home/tony/BigData/Files/wordswithA')\n",
    "\n",
    " # finalWords.saveAsTextFile('file:///home/tony/BigData/Files/wordswithA.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95ea629a-2a61-441a-904f-05ccdcdc5649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('example,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a9b0>),\n",
       " ('SQL', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96aa70>),\n",
       " ('query', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96aad0>),\n",
       " ('method)', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ab30>),\n",
       " ('references', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ab90>),\n",
       " ('throw', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96abf0>),\n",
       " ('an', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ac50>),\n",
       " ('in', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96acb0>),\n",
       " ('this', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ad10>),\n",
       " ('have', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ad70>),\n",
       " ('save', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96add0>),\n",
       " ('as', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ae30>),\n",
       " ('table.', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ae90>),\n",
       " ('do', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96aef0>),\n",
       " ('using', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96af50>),\n",
       " ('.createTempView()',\n",
       "  <pyspark.resultiterable.ResultIterable at 0x7f0c5b96afb0>),\n",
       " ('Spark', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b010>),\n",
       " ('method,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b070>),\n",
       " ('only', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b0d0>),\n",
       " ('name', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b130>),\n",
       " ('of', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b190>),\n",
       " (\"you'd\", <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b1f0>),\n",
       " ('like', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b250>),\n",
       " ('register.', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b2b0>),\n",
       " ('catalog,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b310>),\n",
       " ('but', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b370>),\n",
       " ('is', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b3d0>),\n",
       " ('accessed', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b430>),\n",
       " ('specific', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b490>),\n",
       " ('used', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b4f0>),\n",
       " ('DataFrame.', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b550>),\n",
       " ('safely', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b5b0>),\n",
       " ('new', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b610>),\n",
       " ('was', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b670>),\n",
       " ('there', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b6d0>),\n",
       " ('before,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b730>),\n",
       " ('updates', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b790>),\n",
       " ('already', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b7f0>),\n",
       " (\"You'll\", <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b850>),\n",
       " ('use', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b8b0>),\n",
       " ('into', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b910>),\n",
       " ('For', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b970>),\n",
       " ('a', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96b9d0>),\n",
       " ('(using', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ba30>),\n",
       " ('the', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96ba90>),\n",
       " ('.sql()', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96baf0>),\n",
       " ('that', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bb50>),\n",
       " ('your', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bbb0>),\n",
       " ('DataFrame', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bc10>),\n",
       " ('will', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bc70>),\n",
       " ('error.', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bcd0>),\n",
       " ('To', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bd30>),\n",
       " ('access', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bd90>),\n",
       " ('data', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bdf0>),\n",
       " ('way,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96be50>),\n",
       " ('you', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96beb0>),\n",
       " ('to', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bf10>),\n",
       " ('it', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bf70>),\n",
       " ('temporary', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96bfd0>),\n",
       " ('You', <pyspark.resultiterable.ResultIterable at 0x7f0c5b948070>),\n",
       " ('can', <pyspark.resultiterable.ResultIterable at 0x7f0c5b9480d0>),\n",
       " ('which', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a9e0>),\n",
       " ('takes', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a980>),\n",
       " ('its', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a8f0>),\n",
       " ('argument', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a950>),\n",
       " ('table', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a7d0>),\n",
       " ('This', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a7a0>),\n",
       " ('method', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a6b0>),\n",
       " ('registers', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a5c0>),\n",
       " ('temporary,', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a770>),\n",
       " ('be', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a0b0>),\n",
       " ('from', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a440>),\n",
       " ('SparkSession', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a3b0>),\n",
       " ('create', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a110>),\n",
       " ('There', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969db0>),\n",
       " ('also', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a2c0>),\n",
       " ('.createOrReplaceTempView().',\n",
       "  <pyspark.resultiterable.ResultIterable at 0x7f0c5b969e40>),\n",
       " ('creates', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969cf0>),\n",
       " ('if', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969ed0>),\n",
       " ('nothing', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969f60>),\n",
       " ('or', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969b40>),\n",
       " ('existing', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969c90>),\n",
       " ('one', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969c60>),\n",
       " ('defined.', <pyspark.resultiterable.ResultIterable at 0x7f0c5b96a020>),\n",
       " ('avoid', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969ea0>),\n",
       " ('running', <pyspark.resultiterable.ResultIterable at 0x7f0c5b969bd0>),\n",
       " ('problems', <pyspark.resultiterable.ResultIterable at 0x7f0c7c57f370>),\n",
       " ('with', <pyspark.resultiterable.ResultIterable at 0x7f0c7c7a7be0>),\n",
       " ('duplicate', <pyspark.resultiterable.ResultIterable at 0x7f0c8c1ff4f0>),\n",
       " ('tables.', <pyspark.resultiterable.ResultIterable at 0x7f0c8c1feda0>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task : Word count Program\n",
    "# Read a text file from locally \n",
    "rdd=sc.textFile('file:///home/tony/BigData/Files/Sample.txt')\n",
    "\n",
    "# split these elements into words and ,flatten the nested list into sigle array using flatMap()\n",
    "splitWords=rdd.flatMap(lambda word:word.split())\n",
    "groupWords=splitWords.map(lambda word:(word,1))\n",
    "groupWords2=groupWords.groupByKey()\n",
    "groupWords2.collect()\n",
    "# distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "957d9d66-2837-4385-8788-bc2fcc114aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Task: summing program of all the numbers\n",
    "nums=sc.parallelize([1,2,3,4,5])\n",
    "numsSum=nums.reduce(lambda accum,num:accum+num)\n",
    "# numsSum.collect\n",
    "print(numsSum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
